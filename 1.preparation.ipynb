{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coqa dataset \n",
    "\n",
    "import json\n",
    "\n",
    "path_dataset = \"datasets/coqa/coqa-dev-v1.0.json\"\n",
    "dataset = json.load(open(path_dataset))\n",
    "\n",
    "# for story in tqdm(dataset['data']):\n",
    "target_data = dataset['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_id = target_data['id']\n",
    "story_content = target_data['story']\n",
    "questions = [q_dict[\"input_text\"] for q_dict in target_data['questions']]\n",
    "rounds = len(questions)\n",
    "raw_answers = [target_data['answers']]\n",
    "\n",
    "try:\n",
    "    raw_answers += target_data['additional_answers'].values()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "answers = {} # 1:[\"ans1\",\"ans2\"]\n",
    "for i_round in range(rounds):\n",
    "    answers[i_round+1]=[]\n",
    "\n",
    "for raw_answer_seq in raw_answers:\n",
    "    for raw_answer in raw_answer_seq:\n",
    "        this_round = raw_answer[\"turn_id\"]\n",
    "\n",
    "        this_ori_ans = raw_answer[\"input_text\"].strip(\" \")\n",
    "        if this_ori_ans not in answers[this_round]:\n",
    "            answers[this_round].append(this_ori_ans)\n",
    "\n",
    "        this_ori_story = raw_answer[\"span_text\"].strip(\" \")\n",
    "        if this_ori_story not in answers[this_round]:\n",
    "            answers[this_round].append(this_ori_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1.a Run single dialogue declerative sentence generation\n",
    "from ie_utils import ie_vanilla\n",
    "\n",
    "combined = \"\"\n",
    "    \n",
    "for i in range(len(questions)):\n",
    "    this_ques = questions[i]\n",
    "    this_ans = answers[i+1][0]\n",
    "    combined = combined+\"Round {round_num} - {sentence_q}?\\nRound {round_num} - {sentence_a}.\\n\".format(round_num=i+1,sentence_q=this_ques,sentence_a=this_ans)\n",
    "\n",
    "combined_content = ie_vanilla.extract_declerative_information(combined)\n",
    "target_data[\"combined\"] = combined_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1.b full question extraction\n",
    "\n",
    "combined_json = {}\n",
    "for i in range(len(questions)):\n",
    "    this_ques = questions[i]\n",
    "    this_ans = answers[i+1][0]\n",
    "    round_str = \"Round {round_num}\".format(round_num=i+1)\n",
    "    combined_json[round_str] = {\"Question\": this_ques, \"Answer\":this_ans}\n",
    "    \n",
    "combined_json_content = ie_vanilla.question_resolution(combined_json)\n",
    "\n",
    "target_data[\"original_qa\"] = combined_json\n",
    "target_data[\"full_qa\"] = combined_json_content\n",
    "\n",
    "target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Type, entities, and relation extraction\n",
    "\n",
    "# 1.2.1 Topic extraction\n",
    "topic_content = ie_vanilla.extract_topic(combined_json_content)['topic']\n",
    "target_data[\"topic\"] = topic_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2.2 Entity Types\n",
    "entity_types_content = ie_vanilla.entity_types(input_topic = topic_content, input_dialogue = combined_content)\n",
    "target_data[\"entity_types\"] = entity_types_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2.3 All entities, all relations for dev datasets\n",
    "all_entities_content = ie_vanilla.entity_relations(entity_types = entity_types_content, input_text = combined_content)\n",
    "target_data[\"full_entity_relation\"] = all_entities_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2.4.a Round_entity_relation list\n",
    "round_subgraphs_content = ie_vanilla.round_subgraph(entity_list = all_entities_content[\"entities\"], relation_list = all_entities_content[\"relations\"], dialogue_content=combined_content)\n",
    "target_data[\"round_subgraph\"] = round_subgraphs_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2.4.b Handle unseen round entities and update entity list and relation list\n",
    "\n",
    "all_entity_types = target_data[\"entity_types\"]\n",
    "all_entities = target_data[\"full_entity_relation\"][\"entities\"]\n",
    "all_relations = target_data[\"full_entity_relation\"][\"relations\"]\n",
    "\n",
    "try:\n",
    "    erstools = ie_utils.ie_tools.entity_relation_set_tools(all_entity_types, all_entities, all_relations)\n",
    "    round_keys = list(target_data[\"label\"].keys())\n",
    "    for round_key in round_keys:\n",
    "        # print(round_key)\n",
    "        this_round_question_entities = target_data[\"round_subgraph\"][round_key][\"Question\"][\"entities\"]\n",
    "        this_round_answer_entities = target_data[\"round_subgraph\"][round_key][\"Answer\"][\"entities\"]\n",
    "        this_round_question_relations = target_data[\"round_subgraph\"][round_key][\"Question\"][\"relations\"]\n",
    "        this_round_answer_relations= target_data[\"round_subgraph\"][round_key][\"Answer\"][\"relations\"]\n",
    "        target_data[\"round_subgraph\"][round_key][\"Question\"][\"entities\"] = flatten([erstools.wash_entity(entity) for entity in this_round_question_entities])\n",
    "        target_data[\"round_subgraph\"][round_key][\"Answer\"][\"entities\"] = flatten([erstools.wash_entity(entity) for entity in this_round_answer_entities])\n",
    "        target_data[\"round_subgraph\"][round_key][\"Question\"][\"relations\"] = flatten([erstools.wash_relation(relation) for relation in this_round_question_relations])\n",
    "        target_data[\"round_subgraph\"][round_key][\"Answer\"][\"relations\"] = flatten([erstools.wash_relation(relation) for relation in this_round_answer_relations])\n",
    "\n",
    "    all_entities = erstools.all_entities\n",
    "    all_relations = erstools.all_relations\n",
    "    target_data[\"entity_group_member_mapping\"] = erstools.entity_group_member_mapping_cache\n",
    "    target_data[\"DATA_PROCESS_FLAG\"]=0 # normal\n",
    "\n",
    "except:\n",
    "    try:\n",
    "        erstools = entity_relation_set_tools(all_entity_types, all_entities[0:1], all_relations[0:1], lm)\n",
    "        round_keys = list(target_data[\"label\"].keys())\n",
    "        for round_key in round_keys:\n",
    "            this_round_question_entities = target_data[\"round_subgraph\"][round_key][\"Question\"][\"entities\"]\n",
    "            this_round_answer_entities = target_data[\"round_subgraph\"][round_key][\"Answer\"][\"entities\"]\n",
    "            this_round_question_relations = target_data[\"round_subgraph\"][round_key][\"Question\"][\"relations\"]\n",
    "            this_round_answer_relations= target_data[\"round_subgraph\"][round_key][\"Answer\"][\"relations\"]\n",
    "            target_data[\"round_subgraph\"][round_key][\"Question\"][\"entities\"] = flatten([erstools.wash_entity(entity) for entity in this_round_question_entities])\n",
    "            target_data[\"round_subgraph\"][round_key][\"Answer\"][\"entities\"] = flatten([erstools.wash_entity(entity) for entity in this_round_answer_entities])\n",
    "            target_data[\"round_subgraph\"][round_key][\"Question\"][\"relations\"] = flatten([erstools.wash_relation(relation) for relation in this_round_question_relations])\n",
    "            target_data[\"round_subgraph\"][round_key][\"Answer\"][\"relations\"] = flatten([erstools.wash_relation(relation) for relation in this_round_answer_relations])\n",
    "\n",
    "        all_entities = erstools.all_entities\n",
    "        all_relations = erstools.all_relations\n",
    "        target_data[\"entity_group_member_mapping\"] = erstools.entity_group_member_mapping_cache\n",
    "        target_data[\"DATA_PROCESS_FLAG\"]=10 # rebuild subgraphs \n",
    "    except Exception as e:\n",
    "        print(\"Error in entity relation extraction: \", e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data[\"DATA_PROCESS_FLAG\"] = 0 # or 500 for failed extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "from ie_utils import ie_vanilla\n",
    "from ie_utils import ie_utils\n",
    "\n",
    "result_container = copy.deepcopy(target_data)\n",
    "for key in result_container.keys():\n",
    "    target_data = result_container[key]\n",
    "\n",
    "    story_id = target_data['id']\n",
    "    story_content = target_data['story']\n",
    "    questions = [q_dict[\"input_text\"] for q_dict in target_data['questions']]\n",
    "    rounds = len(questions)\n",
    "    raw_answers = [target_data['answers']]\n",
    "\n",
    "    try:\n",
    "        raw_answers += target_data['additional_answers'].values()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    answers = {} # 1:[\"ans1\",\"ans2\"]\n",
    "    for i_round in range(rounds):\n",
    "        answers[i_round+1]=[]\n",
    "\n",
    "    for raw_answer_seq in raw_answers:\n",
    "        for raw_answer in raw_answer_seq:\n",
    "            this_round = raw_answer[\"turn_id\"]\n",
    "\n",
    "            this_ori_ans = raw_answer[\"input_text\"].strip(\" \")\n",
    "            if this_ori_ans not in answers[this_round]:\n",
    "                answers[this_round].append(this_ori_ans)\n",
    "\n",
    "            this_ori_story = raw_answer[\"span_text\"].strip(\" \")\n",
    "            if this_ori_story not in answers[this_round]:\n",
    "                answers[this_round].append(this_ori_story)\n",
    "    \n",
    "    def p111():\n",
    "        for i in range(len(questions)):\n",
    "            this_ques = questions[i]\n",
    "            this_ans = answers[i+1][0]\n",
    "            combined = combined+\"Round {round_num} - {sentence_q}?\\nRound {round_num} - {sentence_a}.\\n\".format(round_num=i+1,sentence_q=this_ques,sentence_a=this_ans)\n",
    "\n",
    "        combined_content = ie_vanilla.extract_declerative_information(combined)\n",
    "        target_data[\"combined\"] = combined_content\n",
    "\n",
    "    def p111b():\n",
    "        combined_json = {}\n",
    "        for i in range(len(questions)):\n",
    "            this_ques = questions[i]\n",
    "            this_ans = answers[i+1][0]\n",
    "            round_str = \"Round {round_num}\".format(round_num=i+1)\n",
    "            combined_json[round_str] = {\"Question\": this_ques, \"Answer\":this_ans}\n",
    "        \n",
    "        combined_json_content = ie_vanilla.question_resolution(combined_json)\n",
    "\n",
    "        target_data[\"original_qa\"] = combined_json\n",
    "        target_data[\"full_qa\"] = combined_json_content\n",
    "    \n",
    "    def p121():\n",
    "        topic_content = ie_vanilla.extract_topic(combined_json_content)['topic']\n",
    "        target_data[\"topic\"] = topic_content\n",
    "\n",
    "    def p122()\n",
    "        entity_types_content = ie_vanilla.entity_types(input_topic = topic_content, input_dialogue = combined_content)\n",
    "        target_data[\"entity_types\"] = entity_types_content\n",
    "\n",
    "    def p123():\n",
    "        all_entities_content = ie_vanilla.entity_relations(entity_types = entity_types_content, input_text = combined_content)\n",
    "        target_data[\"full_entity_relation\"] = all_entities_content\n",
    "    \n",
    "    def p124a():\n",
    "        round_subgraphs_content = ie_vanilla.round_subgraph(entity_list = all_entities_content[\"entities\"], relation_list = all_entities_content[\"relations\"], dialogue_content=combined_content)\n",
    "        target_data[\"round_subgraph\"] = round_subgraphs_content\n",
    "    def p124b():    \n",
    "        all_entity_types = target_data[\"entity_types\"]\n",
    "        all_entities = target_data[\"full_entity_relation\"][\"entities\"]\n",
    "        all_relations = target_data[\"full_entity_relation\"][\"relations\"]\n",
    "\n",
    "        try:\n",
    "            erstools = ie_utils.ie_tools.entity_relation_set_tools(all_entity_types, all_entities, all_relations)\n",
    "            round_keys = list(target_data[\"label\"].keys())\n",
    "            for round_key in round_keys:\n",
    "                # print(round_key)\n",
    "                this_round_question_entities = target_data[\"round_subgraph\"][round_key][\"Question\"][\"entities\"]\n",
    "                this_round_answer_entities = target_data[\"round_subgraph\"][round_key][\"Answer\"][\"entities\"]\n",
    "                this_round_question_relations = target_data[\"round_subgraph\"][round_key][\"Question\"][\"relations\"]\n",
    "                this_round_answer_relations= target_data[\"round_subgraph\"][round_key][\"Answer\"][\"relations\"]\n",
    "                target_data[\"round_subgraph\"][round_key][\"Question\"][\"entities\"] = flatten([erstools.wash_entity(entity) for entity in this_round_question_entities])\n",
    "                target_data[\"round_subgraph\"][round_key][\"Answer\"][\"entities\"] = flatten([erstools.wash_entity(entity) for entity in this_round_answer_entities])\n",
    "                target_data[\"round_subgraph\"][round_key][\"Question\"][\"relations\"] = flatten([erstools.wash_relation(relation) for relation in this_round_question_relations])\n",
    "                target_data[\"round_subgraph\"][round_key][\"Answer\"][\"relations\"] = flatten([erstools.wash_relation(relation) for relation in this_round_answer_relations])\n",
    "\n",
    "            all_entities = erstools.all_entities\n",
    "            all_relations = erstools.all_relations\n",
    "            target_data[\"entity_group_member_mapping\"] = erstools.entity_group_member_mapping_cache\n",
    "            target_data[\"DATA_PROCESS_FLAG\"]=0 # normal\n",
    "\n",
    "        except:\n",
    "            try:\n",
    "                erstools = entity_relation_set_tools(all_entity_types, all_entities[0:1], all_relations[0:1], lm)\n",
    "                round_keys = list(target_data[\"label\"].keys())\n",
    "                for round_key in round_keys:\n",
    "                    this_round_question_entities = target_data[\"round_subgraph\"][round_key][\"Question\"][\"entities\"]\n",
    "                    this_round_answer_entities = target_data[\"round_subgraph\"][round_key][\"Answer\"][\"entities\"]\n",
    "                    this_round_question_relations = target_data[\"round_subgraph\"][round_key][\"Question\"][\"relations\"]\n",
    "                    this_round_answer_relations= target_data[\"round_subgraph\"][round_key][\"Answer\"][\"relations\"]\n",
    "                    target_data[\"round_subgraph\"][round_key][\"Question\"][\"entities\"] = flatten([erstools.wash_entity(entity) for entity in this_round_question_entities])\n",
    "                    target_data[\"round_subgraph\"][round_key][\"Answer\"][\"entities\"] = flatten([erstools.wash_entity(entity) for entity in this_round_answer_entities])\n",
    "                    target_data[\"round_subgraph\"][round_key][\"Question\"][\"relations\"] = flatten([erstools.wash_relation(relation) for relation in this_round_question_relations])\n",
    "                    target_data[\"round_subgraph\"][round_key][\"Answer\"][\"relations\"] = flatten([erstools.wash_relation(relation) for relation in this_round_answer_relations])\n",
    "\n",
    "                all_entities = erstools.all_entities\n",
    "                all_relations = erstools.all_relations\n",
    "                target_data[\"entity_group_member_mapping\"] = erstools.entity_group_member_mapping_cache\n",
    "                target_data[\"DATA_PROCESS_FLAG\"]=10 # rebuild subgraphs \n",
    "            except Exception as e:\n",
    "                print(\"Error in entity relation extraction: \", e)\n",
    "\n",
    "    retry_count = 0\n",
    "    try: \n",
    "        # Run the processing functions\n",
    "        p111()\n",
    "        p111b()\n",
    "        p121()\n",
    "        p122()\n",
    "        p123()\n",
    "        p124a()\n",
    "        p124b()\n",
    "        target_data[\"DATA_PROCESS_FLAG\"] = 0 # or 500 for failed extraction\n",
    "    except Exception as e:\n",
    "        # retry for 3 times\n",
    "        retry_count += 1\n",
    "        if retry_count < 3:\n",
    "            # Run the processing functions\n",
    "            p111()\n",
    "            p111b()\n",
    "            p121()\n",
    "            p122()\n",
    "            p123()\n",
    "            p124a()\n",
    "            p124b()\n",
    "            target_data[\"DATA_PROCESS_FLAG\"] = 0 # or 500 for failed extraction\n",
    "        else:\n",
    "            print(f\"Failed to process data for story_id {story_id} after 3 retries. Error: {e}\")\n",
    "            target_data[\"DATA_PROCESS_FLAG\"] = 500\n",
    "    \n",
    "    result_container[story_id] = target_data\n",
    "\n",
    "# Save the processed data\n",
    "output_path = \"data/extracted_dev_all_final.json\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(result_container, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
