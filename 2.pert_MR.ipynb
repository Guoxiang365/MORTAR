{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dac7927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import random\n",
    "import copy\n",
    "\n",
    "######## perturbate tools ########\n",
    "\n",
    "def round_shuffler(original_qa: dict):\n",
    "    \"\"\"return:\n",
    "        shuffled QAs\n",
    "        round map: {new_dialogue_key: original_dialogue_key} \n",
    "    \"\"\"\n",
    "    original_round_keys = list(original_qa.keys())\n",
    "    shuffled_round_keys = random.sample(original_round_keys,len(original_round_keys))\n",
    "    new_dialogue = {}\n",
    "    new_dialogue_round_mapping = {}\n",
    "    for count, round_key in enumerate(shuffled_round_keys):\n",
    "        new_round_key = \"Round {}\".format(count+1)\n",
    "        new_dialogue_round_mapping[new_round_key] = round_key\n",
    "        new_dialogue[new_round_key]=original_qa[round_key]\n",
    "    return new_dialogue, new_dialogue_round_mapping\n",
    "\n",
    "\n",
    "def round_reducer(original_qa: dict, drop_round_keys=[], drop_ratio=0.3):\n",
    "    \"\"\"return:\n",
    "        round-reduced QAs\n",
    "        round map: {new_dialogue_key: original_dialogue_key} \n",
    "        list of reduced original rounds: [\"Round x\",...]\n",
    "    \"\"\"\n",
    "    original_round_keys = list(original_qa.keys())\n",
    "    new_dialogue = {}\n",
    "    new_dialogue_round_mapping = {}\n",
    "\n",
    "    # specified round to be moved:\n",
    "    def remove_round_with_inputkeys():\n",
    "        remain_original_round_keys = [item for item in original_round_keys if item not in drop_round_keys]\n",
    "        for i,original_round_key in enumerate(remain_original_round_keys):\n",
    "            new_thisround_key = \"Round {}\".format(i+1)\n",
    "            new_thisround_qa = original_qa[original_round_key]\n",
    "            new_dialogue[new_thisround_key] = new_thisround_qa\n",
    "            new_dialogue_round_mapping[new_thisround_key] = original_round_key\n",
    "        return new_dialogue, new_dialogue_round_mapping, drop_round_keys\n",
    "    \n",
    "    if drop_round_keys:\n",
    "        # specify round keys to remove\n",
    "        return remove_round_with_inputkeys()\n",
    "    else:\n",
    "        # randomly choose drop_ratio(30% default) keys to removed\n",
    "        if drop_ratio<1:\n",
    "            drop_round_keys=random.sample(original_round_keys,int(len(original_round_keys)*drop_ratio))\n",
    "        elif drop_ratio<len(original_round_keys):\n",
    "            drop_round_keys=random.sample(original_round_keys,round(drop_ratio))\n",
    "        else:\n",
    "            raise(ValueError(\"Bad drop_ratio: drop_ratio should less then len(original_round_keys)\"))\n",
    "        return remove_round_with_inputkeys()\n",
    "\n",
    "\n",
    "def round_duplicator(original_qa: dict, duplicate_original_round_keys=[], insert_to_new_dialogue_round_keys=[], duplicate_ratio=0.2):\n",
    "    \"\"\"return:\n",
    "        round-duplicated QAs\n",
    "        round map: {new_dialogue_key:original_dialogue_key} \n",
    "        duplicated original rounds: new_dialogue_key -> original_dialogue_key, original_dialogue_key exist more than once\n",
    "    \"\"\"\n",
    "    original_round_keys = list(original_qa.keys())\n",
    "    new_dialogue = {}\n",
    "    new_dialogue_round_mapping = {}\n",
    "\n",
    "    new_dialogue_duplicated_from_original = {}\n",
    "\n",
    "    # error handling\n",
    "    if len(duplicate_original_round_keys) != len(insert_to_new_dialogue_round_keys): raise(SyntaxError(\"Length not match: duplicate_original_round_keys, insert_to_new_dialogue_round_keys\"))\n",
    "    for round_key in duplicate_original_round_keys:\n",
    "        if round_key not in original_round_keys: raise(KeyError(\"Bad key in duplicate_original_round_keys: {}\".format(round_key)))\n",
    "\n",
    "    def duplicate_round_with_keys():\n",
    "        original_round_keys_reverse = original_round_keys[::-1]\n",
    "        for new_round_key in new_dialogue_round_keys: \n",
    "            # if this round is a specified place to insert duplicated round\n",
    "            if new_round_key in insert_to_new_dialogue_round_keys: \n",
    "                thisnewround_use_original_round_key = duplicate_original_round_keys[insert_to_new_dialogue_round_keys.index(new_round_key)]\n",
    "                new_dialogue[new_round_key] = original_qa[thisnewround_use_original_round_key]\n",
    "                new_dialogue_round_mapping[new_round_key] = thisnewround_use_original_round_key\n",
    "                new_dialogue_duplicated_from_original[new_round_key] = thisnewround_use_original_round_key\n",
    "            # follow original sequence\n",
    "            else: \n",
    "                thisnewround_use_original_round_key = original_round_keys_reverse.pop()\n",
    "                new_dialogue[new_round_key] = original_qa[thisnewround_use_original_round_key]\n",
    "                new_dialogue_round_mapping[new_round_key] = thisnewround_use_original_round_key\n",
    "        return new_dialogue, new_dialogue_round_mapping, new_dialogue_duplicated_from_original\n",
    "\n",
    "    # if specified round to duplicate and round number to place:\n",
    "    if duplicate_original_round_keys:\n",
    "        new_dialogue_round_keys = original_round_keys+[\"Round {}\".format(len(original_round_keys)+new_round+1) for new_round in range(len(duplicate_original_round_keys))]\n",
    "        return duplicate_round_with_keys()\n",
    "    \n",
    "    # randomly choose rounds to duplicate and places to insert\n",
    "    else:\n",
    "        if duplicate_ratio<1:\n",
    "            duplicate_original_round_keys = random.sample(original_round_keys, int(len(original_round_keys)*duplicate_ratio))\n",
    "            new_dialogue_round_keys = original_round_keys+[\"Round {}\".format(len(original_round_keys)+new_round+1) for new_round in range(len(duplicate_original_round_keys))]\n",
    "            insert_to_new_dialogue_round_keys = random.sample(new_dialogue_round_keys, int(len(original_round_keys)*duplicate_ratio))\n",
    "            return duplicate_round_with_keys()\n",
    "        elif duplicate_ratio<len(original_round_keys):\n",
    "            duplicate_original_round_keys = random.sample(original_round_keys, round(duplicate_ratio))\n",
    "            new_dialogue_round_keys = original_round_keys+[\"Round {}\".format(len(original_round_keys)+new_round+1) for new_round in range(len(duplicate_original_round_keys))]\n",
    "            insert_to_new_dialogue_round_keys = random.sample(new_dialogue_round_keys, round(duplicate_ratio))\n",
    "            return duplicate_round_with_keys()\n",
    "        else:\n",
    "            raise(ValueError(\"Bad duplicate_ratio: duplicate_ratio should less then len(original_round_keys)\"))\n",
    "\n",
    "\n",
    "def round_reduce_shuffle(original_qa: dict, drop_round_keys=[], drop_ratio=0.3):\n",
    "    \"\"\"return:\n",
    "        round-reduced-shuffled QAs\n",
    "        round map: {new_dialogue_key: original_dialogue_key} \n",
    "        list of reduced original rounds: [\"Round x\",...]\n",
    "    \"\"\"\n",
    "    reduced_dialogue, reduced_dialogue_round_mapping, dropped_round_keys = round_reducer(original_qa, drop_round_keys, drop_ratio)\n",
    "    shuffled_reduced_dialogue, shuffled_reduced_dialogue_round_mapping = round_shuffler(reduced_dialogue)\n",
    "    to_original_mapping={}\n",
    "    for round_key in list(shuffled_reduced_dialogue.keys()):\n",
    "        to_original_mapping[round_key] = reduced_dialogue_round_mapping[shuffled_reduced_dialogue_round_mapping[round_key]]\n",
    "    return shuffled_reduced_dialogue, to_original_mapping, dropped_round_keys\n",
    "\n",
    "def round_shuffle_duplicate(original_qa: dict, duplicate_original_round_keys=[], insert_to_new_dialogue_round_keys=[], duplicate_ratio=0.2):\n",
    "    \"\"\"return:\n",
    "        round-duplicated-shuffled QAs\n",
    "        round map: {new_dialogue_key: original_dialogue_key}\n",
    "        duplicated original rounds: {new_dialogue_key: original_dialogue_key}, original_dialogue_key exist more than once. might not that useful\n",
    "    \"\"\"\n",
    "    shuffled_dialogue, shuffled_dialogue_round_mapping = round_shuffler(original_qa)\n",
    "    shuffled_duplicated_dialogue, shuffled_duplicated_dialogue_round_mapping, shuffled_duplicated_dialogue_duplicated_from_original = round_duplicator(shuffled_dialogue, duplicate_original_round_keys, insert_to_new_dialogue_round_keys, duplicate_ratio)\n",
    "    \n",
    "    to_original_mapping={}\n",
    "    to_original_info = {}\n",
    "\n",
    "    for round_key in list(shuffled_duplicated_dialogue.keys()):\n",
    "        to_original_mapping[round_key] = shuffled_dialogue_round_mapping[shuffled_duplicated_dialogue_round_mapping[round_key]]\n",
    "\n",
    "    for round_key in list(shuffled_duplicated_dialogue_duplicated_from_original.keys()):\n",
    "        to_original_info[round_key] = shuffled_dialogue_round_mapping[shuffled_duplicated_dialogue_round_mapping[round_key]]\n",
    "        \n",
    "    return shuffled_duplicated_dialogue, to_original_mapping, shuffled_duplicated_dialogue_duplicated_from_original, to_original_info\n",
    "\n",
    "######## verify tools ########\n",
    "\n",
    "wh_words=[\"who\", \"what\", \"where\", \"when\", \"why\", \"which\", \"whose\", \"whom\", \"how\"]\n",
    "\n",
    "aux_words={\"be\": [\"am\", \"is\", \"are\", \"was\", \"were\"],\n",
    "           \"have\": [\"has\", \"have\", \"had\"],\n",
    "           \"do\": [\"do\", \"does\", \"did\"],\n",
    "           \"modal Verbs\":[\"can\", \"could\", \"will\", \"would\", \"shall\", \"should\", \"may\", \"might\"]}\n",
    "\n",
    "pronouns={\n",
    "    \"Personal Pronouns\":[\"I\", \"you\", \"he\", \"she\", \"it\", \"we\", \"they\", \"me\", \"him\", \"her\", \"us\", \"them\"],\n",
    "    \"Possessive Pronouns\":[\"mine\", \"yours\", \"his\", \"hers\", \"ours\", \"theirs\"],\n",
    "    \"Possessive Adjectives\":[\"my\", \"your\", \"his\", \"her\", \"its\", \"our\", \"their\"],\n",
    "    \"Reflexive Pronouns\":[\"myself\", \"yourself\", \"himself\", \"herself\", \"itself\", \"ourselves\", \"themselves\"],\n",
    "    \"Demonstrative Pronouns\":[\"this\", \"that\", \"these\", \"those\"], # coreference models can not handle demonstrative pronouns\n",
    "}\n",
    "\n",
    "regular_pronouns={\n",
    "    \"Personal Pronouns\":[\"he\", \"she\", \"it\", \"they\", \"him\", \"her\", \"them\"],\n",
    "    \"Possessive Pronouns\":[\"yours\", \"his\", \"hers\", \"theirs\"],\n",
    "    \"Possessive Adjectives\":[\"your\", \"his\", \"her\", \"its\", \"their\"],\n",
    "    \"Reflexive Pronouns\":[\"himself\", \"herself\", \"itself\", \"themselves\"],\n",
    "}\n",
    "\n",
    "DT_pronoun = {\n",
    "    \"Demonstrative Pronouns\":[\"this\", \"that\", \"these\", \"those\"],\n",
    "    \"Indefinite Pronouns\":[\"all\", \"another\", \"any\", \"anybody\", \"anyone\", \"both\", \"each\", \"either\", \"everyone\", \"few\", \"many\", \"none\", \"one\", \"some\", \"somebody\", \"several\"],\n",
    " }\n",
    "\n",
    "\n",
    "all_aux_words = []\n",
    "for key in aux_words.keys():\n",
    "    for item in aux_words[key]:\n",
    "        if item not in all_aux_words:\n",
    "            all_aux_words.append(item)\n",
    "\n",
    "all_pronouns = []\n",
    "for key in pronouns.keys():\n",
    "    for item in pronouns[key]:\n",
    "        if item not in all_pronouns:\n",
    "            all_pronouns.append(item)\n",
    "\n",
    "all_regular_pronouns = []\n",
    "for key in regular_pronouns.keys():\n",
    "    for item in regular_pronouns[key]:\n",
    "        if item not in all_regular_pronouns:\n",
    "            all_regular_pronouns.append(item)\n",
    "\n",
    "import spacy\n",
    "import coreferee\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "nlp.add_pipe('coreferee')\n",
    "\n",
    "def flatten(lst):\n",
    "    flat_list = []\n",
    "    for item in lst:\n",
    "        if isinstance(item, list):\n",
    "            flat_list.extend(flatten(item))  # Recursively flatten the list\n",
    "        else:\n",
    "            flat_list.append(item)\n",
    "    return flat_list\n",
    "\n",
    "def self_resolvable(input_text, PRINT_FLAG=False):\n",
    "    \"\"\"\n",
    "    input: input_text, PRINT_FLAG(opt)\n",
    "    output: FLAG_resolvable, LIST_remain\n",
    "    Note: coreference models can not handle demonstrative pronouns (this that etc.) This will be handled by context subgraph coverage module\n",
    "    \"\"\"\n",
    "    doc = nlp(input_text)\n",
    "\n",
    "    FLAG_resolved = True\n",
    "\n",
    "    # if len(question) <= 3\n",
    "    word_count = len([token for token in doc if not token.is_punct])\n",
    "    if word_count <= 3: \n",
    "        FLAG_resolved = False\n",
    "    \n",
    "    # pronoun usage\n",
    "    pronoun_extraction_result = set([token.text.lower() for token in doc if token.text.lower() in all_pronouns and token.pos_ == \"PRON\"])\n",
    "    if PRINT_FLAG: print(pronoun_extraction_result)\n",
    "\n",
    "    # self-resolved pronouns\n",
    "    coreference_res = doc._.coref_chains\n",
    "    pronouns_spacy = []\n",
    "    for chain in coreference_res:\n",
    "        for mention in chain:\n",
    "            for pos in mention:\n",
    "                pronouns_spacy.append(pos)\n",
    "    pronouns_self_resolved = set([str(doc[pos]).lower() for pos in pronouns_spacy])\n",
    "    if PRINT_FLAG: print(pronouns_self_resolved)\n",
    "\n",
    "    # check if all used pronouns are self-resolved:\n",
    "    LIST_remain = []\n",
    "    for pronoun in pronoun_extraction_result:\n",
    "        if pronoun.lower() not in pronouns_self_resolved:\n",
    "            LIST_remain.append(pronoun.lower())\n",
    "    if LIST_remain:\n",
    "        FLAG_resolved = False\n",
    "    return FLAG_resolved, LIST_remain\n",
    "\n",
    "def story_resolvable(story_content, input_text, LIST_remain=[], PRINT_FLAG=False):\n",
    "    story_doc = nlp(story_content)\n",
    "\n",
    "    if PRINT_FLAG:\n",
    "        for token in story_doc:\n",
    "            print(f\"{token.text}: {token.pos_} ({token.tag_})\")\n",
    "\n",
    "    story_pronoun_extraction_result = set([token.text.lower() for token in story_doc if token.text.lower() in all_regular_pronouns and token.pos_ == \"PRON\"])\n",
    "    if PRINT_FLAG: print(\"Story used:\",story_pronoun_extraction_result)\n",
    "    \n",
    "    # if no LIST_remain provided, extract it\n",
    "    if not LIST_remain:\n",
    "        _, LIST_remain = self_resolvable(input_text, PRINT_FLAG)\n",
    "    if PRINT_FLAG: print(\"LIST_remain\",LIST_remain)\n",
    "\n",
    "    # judge if context resolvable\n",
    "    FLAG_resolved = True\n",
    "    for pronoun in LIST_remain:\n",
    "        if pronoun not in story_pronoun_extraction_result:\n",
    "            FLAG_resolved = False\n",
    "    return FLAG_resolved\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "def graph_maker(node_list, edge_list):\n",
    "    G = nx.MultiGraph()\n",
    "    if node_list:\n",
    "        for node in node_list:\n",
    "            if node is None: continue\n",
    "            \n",
    "            node_name = node[\"name\"]\n",
    "            node_type = node[\"type\"]\n",
    "            # node_desc = node[\"description\"]\n",
    "            if not G.has_node(node_name):\n",
    "                G.add_node(node_name, ntype = node_type)\n",
    "    if edge_list:\n",
    "        for edge in edge_list:\n",
    "            if edge is None: continue\n",
    "            \n",
    "            edge_name = edge[\"relationship\"]\n",
    "            from_node = edge[\"source_entity\"]\n",
    "            to_node = edge[\"target_entity\"]\n",
    "            # edge_desc = edge[\"relationship_description\"]\n",
    "            if G.has_node(from_node) and G.has_node(to_node) and not G.has_edge(from_node, to_node, edge_name):\n",
    "                G.add_edge(from_node, to_node, relationship=edge_name)\n",
    "            else:\n",
    "                continue\n",
    "    return G\n",
    "\n",
    "def graph_differ(big_graph: nx.MultiGraph, small_graph: nx.MultiGraph) -> nx.MultiGraph:\n",
    "    nodes_diff = set(big_graph.nodes()) - set(small_graph.nodes())\n",
    "    # edges_diff = set(big_graph.edges()) - set(small_graph.edges())\n",
    "    G_diff = nx.MultiGraph()\n",
    "    G_diff.add_nodes_from(nodes_diff)\n",
    "    # G_diff.add_edges_from(edges_diff)\n",
    "    return G_diff\n",
    "\n",
    "def context_resolvable(thisround_short_q_graph, thisround_full_q_graph, thisround_context_qa_graph):\n",
    "    # print(thisround_short_q_graph, thisround_full_q_graph, thisround_context_qa_graph) \n",
    "    G_thisround_short_q = graph_maker(thisround_short_q_graph[\"entities\"], thisround_short_q_graph[\"relations\"])\n",
    "    G_thisround_full_q = graph_maker(thisround_full_q_graph[\"entities\"], thisround_full_q_graph[\"relations\"])\n",
    "    G_thisround_completement = graph_differ(G_thisround_full_q, G_thisround_short_q)\n",
    "    G_thisround_context = graph_maker(thisround_context_qa_graph[\"entities\"] , thisround_context_qa_graph[\"relations\"] )\n",
    "    GM = nx.algorithms.isomorphism.GraphMatcher(G_thisround_context, G_thisround_completement)\n",
    "    FLAG_completement_is_subgraph = GM.subgraph_is_isomorphic()\n",
    "    return FLAG_completement_is_subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efb4abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original\n",
    "\n",
    "import json\n",
    "import tqdm\n",
    "import copy\n",
    "\n",
    "path_dataset = \"data/extracted_dev_all_final_update_3_strict.json\"\n",
    "dataset_dev_full= json.load(open(path_dataset))\n",
    "\n",
    "all_keys = list(dataset_dev_full.keys())[:]\n",
    "\n",
    "dataset_new_dialogue = {}\n",
    "\n",
    "update_answer_counter = 0\n",
    "\n",
    "for thisdialogue_key in tqdm.tqdm(all_keys):\n",
    "\n",
    "    this_dialogue = copy.deepcopy(dataset_dev_full[thisdialogue_key])\n",
    "    if this_dialogue[\"DATA_PROCESS_FLAG\"] >= 500: continue\n",
    "\n",
    "    original_qa = this_dialogue[\"original_qa\"]\n",
    "    this_dialogue_story_content = this_dialogue[\"story_material\"]\n",
    "\n",
    "    # make new dialogue\n",
    "    perturbed_dialogue = original_qa\n",
    "    perturbed_dialogue_round_mapping = {}\n",
    "    perturbed_dialogue_all_round_keys = list(perturbed_dialogue.keys())\n",
    "\n",
    "    ##### below\n",
    "    list_previous_round_answerabilty = [] \n",
    "    ##### up\n",
    "    for key in perturbed_dialogue_all_round_keys:\n",
    "        perturbed_dialogue_round_mapping[key] = key\n",
    "\n",
    "    for thisround_i, thisround_key in enumerate(perturbed_dialogue_all_round_keys):\n",
    "        thisround_is_original_round = perturbed_dialogue_round_mapping[thisround_key]\n",
    "\n",
    "        thisround_oriqa_q = perturbed_dialogue[thisround_key][\"Question\"]\n",
    "        thisround_oriqa_a = perturbed_dialogue[thisround_key][\"Answer\"]\n",
    "\n",
    "        thisround_oriqa_q_graph = this_dialogue[\"round_original_question_subgraph\"][thisround_is_original_round]\n",
    "        thisround_fullqa_q_graph = this_dialogue[\"round_subgraph\"][thisround_is_original_round][\"Question\"]\n",
    "\n",
    "        thisround_context_qa_graph = {\n",
    "            \"entities\":[],\n",
    "            \"relations\":[]\n",
    "        }\n",
    "        ##### below\n",
    "        for context_round_i in range(thisround_i): \n",
    "            analysis_thisround_is_original  = perturbed_dialogue_round_mapping[perturbed_dialogue_all_round_keys[context_round_i]]\n",
    "\n",
    "            thisround_context_qa_graph[\"entities\"].append(this_dialogue[\"round_original_question_subgraph\"][analysis_thisround_is_original][\"entities\"])\n",
    "            thisround_context_qa_graph[\"relations\"].append(this_dialogue[\"round_original_question_subgraph\"][analysis_thisround_is_original][\"relations\"])\n",
    "            \n",
    "            # if previous round question is answerable, put all information in context, else just keep original question info, duplicated info will be filtered autmatically\n",
    "            if list_previous_round_answerabilty[context_round_i]:\n",
    "                thisround_context_qa_graph[\"entities\"].append(this_dialogue[\"round_subgraph\"][analysis_thisround_is_original][\"Question\"][\"entities\"])\n",
    "                thisround_context_qa_graph[\"relations\"].append(this_dialogue[\"round_subgraph\"][analysis_thisround_is_original][\"Question\"][\"relations\"])\n",
    "                thisround_context_qa_graph[\"entities\"].append(this_dialogue[\"round_subgraph\"][analysis_thisround_is_original][\"Answer\"][\"entities\"])\n",
    "                thisround_context_qa_graph[\"relations\"].append(this_dialogue[\"round_subgraph\"][analysis_thisround_is_original][\"Answer\"][\"relations\"])\n",
    "        ##### up\n",
    "        thisround_context_qa_graph[\"entities\"] = flatten(thisround_context_qa_graph[\"entities\"])\n",
    "        thisround_context_qa_graph[\"relations\"] = flatten(thisround_context_qa_graph[\"relations\"])\n",
    "\n",
    "        FLAG_self_resolvable, _ = self_resolvable(thisround_oriqa_q)   \n",
    "        FLAG_story_resolvable = story_resolvable(this_dialogue_story_content, thisround_oriqa_q)\n",
    "        FLAG_context_resolvable = context_resolvable(thisround_oriqa_q_graph, thisround_fullqa_q_graph, thisround_context_qa_graph)\n",
    "        ##### below\n",
    "        list_previous_round_answerabilty.append(FLAG_self_resolvable or FLAG_story_resolvable or FLAG_context_resolvable) and (\"unknown\" not in thisround_oriqa_a.lower())\n",
    "        ##### up\n",
    "        if FLAG_self_resolvable or FLAG_story_resolvable or FLAG_context_resolvable or (\"unknown\" in thisround_oriqa_a.lower()):\n",
    "            perturbed_dialogue[thisround_key][\"FLAG_answer_changed\"] = False\n",
    "            pass\n",
    "        else:\n",
    "            perturbed_dialogue[thisround_key][\"Answer_original\"] = thisround_oriqa_a\n",
    "            perturbed_dialogue[thisround_key][\"Answer\"] = \"unknown\"\n",
    "            perturbed_dialogue[thisround_key][\"FLAG_answer_changed\"] = True\n",
    "            update_answer_counter+=1\n",
    "\n",
    "        perturbed_dialogue[thisround_key][\"is_original_round\"] = thisround_is_original_round\n",
    "        \n",
    "        perturbed_dialogue[thisround_key][\"FLAG_self_resolvable\"] = FLAG_self_resolvable\n",
    "        perturbed_dialogue[thisround_key][\"FLAG_story_resolvable\"] = FLAG_story_resolvable\n",
    "        perturbed_dialogue[thisround_key][\"FLAG_context_resolvable\"] = FLAG_context_resolvable\n",
    "\n",
    "    dataset_new_dialogue[thisdialogue_key] = copy.deepcopy(perturbed_dialogue)\n",
    "\n",
    "##### below        \n",
    "with open(\"data/P0_round_original.json\", \"w\") as f:\n",
    "    json.dump(dataset_new_dialogue, f, indent=4)\n",
    "##### up\n",
    "\n",
    "print(\"{} changed answer.\".format(update_answer_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c77b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P1: Dialogue round shuffle\n",
    "path_dataset = \"data/extracted_dev_all_final_update_3_strict.json\"\n",
    "dataset_dev_full= json.load(open(path_dataset))\n",
    "\n",
    "all_keys = list(dataset_dev_full.keys())[:]\n",
    "\n",
    "dataset_new_dialogue = {}\n",
    "\n",
    "update_answer_counter = 0\n",
    "\n",
    "for thisdialogue_key in tqdm.tqdm(all_keys):\n",
    "    if update_answer_counter/10 == 0: print(\"update_answer_counter:\",update_answer_counter)\n",
    "# thisdialogue_key = all_keys[0]\n",
    "\n",
    "    this_dialogue = copy.deepcopy(dataset_dev_full[thisdialogue_key])\n",
    "    if this_dialogue[\"DATA_PROCESS_FLAG\"] >= 500: continue\n",
    "\n",
    "    original_qa = this_dialogue[\"original_qa\"]\n",
    "    this_dialogue_story_content = this_dialogue[\"story_material\"]\n",
    "\n",
    "    # make new dialogue\n",
    "    perturbed_dialogue, perturbed_dialogue_round_mapping = round_shuffler(original_qa)\n",
    "    perturbed_dialogue_all_round_keys = list(perturbed_dialogue.keys())\n",
    "\n",
    "    ##### below\n",
    "    list_previous_round_answerabilty = [] \n",
    "    ##### up\n",
    "\n",
    "    for thisround_i, thisround_key in enumerate(perturbed_dialogue_all_round_keys):\n",
    "        thisround_is_original_round = perturbed_dialogue_round_mapping[thisround_key]\n",
    "\n",
    "        thisround_oriqa_q = perturbed_dialogue[thisround_key][\"Question\"]\n",
    "        thisround_oriqa_a = perturbed_dialogue[thisround_key][\"Answer\"]\n",
    "\n",
    "        thisround_oriqa_q_graph = this_dialogue[\"round_original_question_subgraph\"][thisround_is_original_round]\n",
    "        thisround_fullqa_q_graph = this_dialogue[\"round_subgraph\"][thisround_is_original_round][\"Question\"]\n",
    "\n",
    "        thisround_context_qa_graph = {\n",
    "            \"entities\":[],\n",
    "            \"relations\":[]\n",
    "        }\n",
    "        ##### below\n",
    "        for context_round_i in range(thisround_i): \n",
    "            analysis_thisround_is_original  = perturbed_dialogue_round_mapping[perturbed_dialogue_all_round_keys[context_round_i]]\n",
    "\n",
    "            thisround_context_qa_graph[\"entities\"].append(this_dialogue[\"round_original_question_subgraph\"][analysis_thisround_is_original][\"entities\"])\n",
    "            thisround_context_qa_graph[\"relations\"].append(this_dialogue[\"round_original_question_subgraph\"][analysis_thisround_is_original][\"relations\"])\n",
    "            \n",
    "            # if previous round question is answerable, put all information in context, else just keep original question info, duplicated info will be filtered autmatically\n",
    "            if list_previous_round_answerabilty[context_round_i]:\n",
    "                thisround_context_qa_graph[\"entities\"].append(this_dialogue[\"round_subgraph\"][analysis_thisround_is_original][\"Question\"][\"entities\"])\n",
    "                thisround_context_qa_graph[\"relations\"].append(this_dialogue[\"round_subgraph\"][analysis_thisround_is_original][\"Question\"][\"relations\"])\n",
    "                thisround_context_qa_graph[\"entities\"].append(this_dialogue[\"round_subgraph\"][analysis_thisround_is_original][\"Answer\"][\"entities\"])\n",
    "                thisround_context_qa_graph[\"relations\"].append(this_dialogue[\"round_subgraph\"][analysis_thisround_is_original][\"Answer\"][\"relations\"])\n",
    "        ##### up\n",
    "        thisround_context_qa_graph[\"entities\"] = flatten(thisround_context_qa_graph[\"entities\"])\n",
    "        thisround_context_qa_graph[\"relations\"] = flatten(thisround_context_qa_graph[\"relations\"])\n",
    "\n",
    "        FLAG_self_resolvable, _ = self_resolvable(thisround_oriqa_q)   \n",
    "        FLAG_story_resolvable = story_resolvable(this_dialogue_story_content, thisround_oriqa_q)\n",
    "        FLAG_context_resolvable = context_resolvable(thisround_oriqa_q_graph, thisround_fullqa_q_graph, thisround_context_qa_graph)\n",
    "        ##### below\n",
    "        list_previous_round_answerabilty.append(FLAG_self_resolvable or FLAG_story_resolvable or FLAG_context_resolvable) and (\"unknown\" not in thisround_oriqa_a.lower())\n",
    "        ##### up\n",
    "        if FLAG_self_resolvable or FLAG_story_resolvable or FLAG_context_resolvable or (\"unknown\" in thisround_oriqa_a.lower()):\n",
    "            perturbed_dialogue[thisround_key][\"FLAG_answer_changed\"] = False\n",
    "            pass\n",
    "        else:\n",
    "            perturbed_dialogue[thisround_key][\"Answer_original\"] = thisround_oriqa_a\n",
    "            perturbed_dialogue[thisround_key][\"Answer\"] = \"unknown\"\n",
    "            perturbed_dialogue[thisround_key][\"FLAG_answer_changed\"] = True\n",
    "            update_answer_counter+=1\n",
    "\n",
    "        perturbed_dialogue[thisround_key][\"is_original_round\"] = thisround_is_original_round\n",
    "        \n",
    "        perturbed_dialogue[thisround_key][\"FLAG_self_resolvable\"] = FLAG_self_resolvable\n",
    "        perturbed_dialogue[thisround_key][\"FLAG_story_resolvable\"] = FLAG_story_resolvable\n",
    "        perturbed_dialogue[thisround_key][\"FLAG_context_resolvable\"] = FLAG_context_resolvable\n",
    "\n",
    "    dataset_new_dialogue[thisdialogue_key] = copy.deepcopy(perturbed_dialogue)\n",
    "        \n",
    "with open(\"data/P1_round_shuffle.json\", \"w\") as f:\n",
    "    json.dump(dataset_new_dialogue, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5d5381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P2: Dialogue round reduce\n",
    "path_dataset = \"data/extracted_dev_all_final_update_3_strict.json\"\n",
    "dataset_dev_full= json.load(open(path_dataset))\n",
    "\n",
    "all_keys = list(dataset_dev_full.keys())[:]\n",
    "\n",
    "dataset_new_dialogue = {}\n",
    "\n",
    "update_answer_counter = 0\n",
    "\n",
    "for thisdialogue_key in tqdm.tqdm(all_keys):\n",
    "\n",
    "    this_dialogue = copy.deepcopy(dataset_dev_full[thisdialogue_key])\n",
    "    if this_dialogue[\"DATA_PROCESS_FLAG\"] >= 500: continue\n",
    "\n",
    "    original_qa = this_dialogue[\"original_qa\"]\n",
    "    this_dialogue_story_content = this_dialogue[\"story_material\"]\n",
    "\n",
    "    # make new dialogue\n",
    "    perturbed_dialogue, perturbed_dialogue_round_mapping, drop_round_keys = round_reducer(original_qa)\n",
    "    perturbed_dialogue_all_round_keys = list(perturbed_dialogue.keys())\n",
    "    ##### below\n",
    "    list_previous_round_answerabilty = [] \n",
    "    ##### up\n",
    "    for thisround_i, thisround_key in enumerate(perturbed_dialogue_all_round_keys):\n",
    "        thisround_is_original_round = perturbed_dialogue_round_mapping[thisround_key]\n",
    "\n",
    "        thisround_oriqa_q = perturbed_dialogue[thisround_key][\"Question\"]\n",
    "        thisround_oriqa_a = perturbed_dialogue[thisround_key][\"Answer\"]\n",
    "\n",
    "        thisround_oriqa_q_graph = this_dialogue[\"round_original_question_subgraph\"][thisround_is_original_round]\n",
    "        thisround_fullqa_q_graph = this_dialogue[\"round_subgraph\"][thisround_is_original_round][\"Question\"]\n",
    "\n",
    "        thisround_context_qa_graph = {\n",
    "            \"entities\":[],\n",
    "            \"relations\":[]\n",
    "        }\n",
    "        ##### below\n",
    "        for context_round_i in range(thisround_i): \n",
    "            analysis_thisround_is_original  = perturbed_dialogue_round_mapping[perturbed_dialogue_all_round_keys[context_round_i]]\n",
    "\n",
    "            thisround_context_qa_graph[\"entities\"].append(this_dialogue[\"round_original_question_subgraph\"][analysis_thisround_is_original][\"entities\"])\n",
    "            thisround_context_qa_graph[\"relations\"].append(this_dialogue[\"round_original_question_subgraph\"][analysis_thisround_is_original][\"relations\"])\n",
    "            \n",
    "            # if previous round question is answerable, put all information in context, else just keep original question info, duplicated info will be filtered autmatically\n",
    "            if list_previous_round_answerabilty[context_round_i]:\n",
    "                thisround_context_qa_graph[\"entities\"].append(this_dialogue[\"round_subgraph\"][analysis_thisround_is_original][\"Question\"][\"entities\"])\n",
    "                thisround_context_qa_graph[\"relations\"].append(this_dialogue[\"round_subgraph\"][analysis_thisround_is_original][\"Question\"][\"relations\"])\n",
    "                thisround_context_qa_graph[\"entities\"].append(this_dialogue[\"round_subgraph\"][analysis_thisround_is_original][\"Answer\"][\"entities\"])\n",
    "                thisround_context_qa_graph[\"relations\"].append(this_dialogue[\"round_subgraph\"][analysis_thisround_is_original][\"Answer\"][\"relations\"])\n",
    "        ##### up\n",
    "        thisround_context_qa_graph[\"entities\"] = flatten(thisround_context_qa_graph[\"entities\"])\n",
    "        thisround_context_qa_graph[\"relations\"] = flatten(thisround_context_qa_graph[\"relations\"])\n",
    "\n",
    "        FLAG_self_resolvable, _ = self_resolvable(thisround_oriqa_q)   \n",
    "        FLAG_story_resolvable = story_resolvable(this_dialogue_story_content, thisround_oriqa_q)\n",
    "        FLAG_context_resolvable = context_resolvable(thisround_oriqa_q_graph, thisround_fullqa_q_graph, thisround_context_qa_graph)\n",
    "        ##### below\n",
    "        list_previous_round_answerabilty.append(FLAG_self_resolvable or FLAG_story_resolvable or FLAG_context_resolvable) and (\"unknown\" not in thisround_oriqa_a.lower())\n",
    "        ##### up\n",
    "        if FLAG_self_resolvable or FLAG_story_resolvable or FLAG_context_resolvable or (\"unknown\" in thisround_oriqa_a.lower()):\n",
    "            perturbed_dialogue[thisround_key][\"FLAG_answer_changed\"] = False\n",
    "            pass\n",
    "        else:\n",
    "            perturbed_dialogue[thisround_key][\"Answer_original\"] = thisround_oriqa_a\n",
    "            perturbed_dialogue[thisround_key][\"Answer\"] = \"unknown\"\n",
    "            perturbed_dialogue[thisround_key][\"FLAG_answer_changed\"] = True\n",
    "            update_answer_counter+=1\n",
    "\n",
    "        perturbed_dialogue[thisround_key][\"is_original_round\"] = thisround_is_original_round\n",
    "        \n",
    "        perturbed_dialogue[thisround_key][\"FLAG_self_resolvable\"] = FLAG_self_resolvable\n",
    "        perturbed_dialogue[thisround_key][\"FLAG_story_resolvable\"] = FLAG_story_resolvable\n",
    "        perturbed_dialogue[thisround_key][\"FLAG_context_resolvable\"] = FLAG_context_resolvable\n",
    "\n",
    "    dataset_new_dialogue[thisdialogue_key] = copy.deepcopy(perturbed_dialogue)\n",
    "        \n",
    "with open(\"data/P2_round_reduce.json\", \"w\") as f:\n",
    "    json.dump(dataset_new_dialogue, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633eedd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P3: Dialogue round duplicate\n",
    "path_dataset = \"data/extracted_dev_all_final_update_3_strict.json\"\n",
    "dataset_dev_full= json.load(open(path_dataset))\n",
    "\n",
    "all_keys = list(dataset_dev_full.keys())[:]\n",
    "\n",
    "dataset_new_dialogue = {}\n",
    "\n",
    "update_answer_counter = 0\n",
    "\n",
    "for thisdialogue_key in tqdm.tqdm(all_keys):\n",
    "\n",
    "    this_dialogue = copy.deepcopy(dataset_dev_full[thisdialogue_key])\n",
    "    if this_dialogue[\"DATA_PROCESS_FLAG\"] >= 500: continue\n",
    "\n",
    "    original_qa = this_dialogue[\"original_qa\"]\n",
    "    this_dialogue_story_content = this_dialogue[\"story_material\"]\n",
    "\n",
    "    # make new dialogue\n",
    "    perturbed_dialogue, perturbed_dialogue_round_mapping, _ = round_duplicator(original_qa)\n",
    "    perturbed_dialogue_all_round_keys = list(perturbed_dialogue.keys())\n",
    "    ##### below\n",
    "    list_previous_round_answerabilty = [] \n",
    "    ##### up\n",
    "    for thisround_i, thisround_key in enumerate(perturbed_dialogue_all_round_keys):\n",
    "        thisround_is_original_round = perturbed_dialogue_round_mapping[thisround_key]\n",
    "\n",
    "        thisround_oriqa_q = perturbed_dialogue[thisround_key][\"Question\"]\n",
    "        thisround_oriqa_a = perturbed_dialogue[thisround_key][\"Answer\"]\n",
    "\n",
    "        thisround_oriqa_q_graph = this_dialogue[\"round_original_question_subgraph\"][thisround_is_original_round]\n",
    "        thisround_fullqa_q_graph = this_dialogue[\"round_subgraph\"][thisround_is_original_round][\"Question\"]\n",
    "\n",
    "        thisround_context_qa_graph = {\n",
    "            \"entities\":[],\n",
    "            \"relations\":[]\n",
    "        }\n",
    "        ##### below\n",
    "        for context_round_i in range(thisround_i): \n",
    "            analysis_thisround_is_original  = perturbed_dialogue_round_mapping[perturbed_dialogue_all_round_keys[context_round_i]]\n",
    "\n",
    "            thisround_context_qa_graph[\"entities\"].append(this_dialogue[\"round_original_question_subgraph\"][analysis_thisround_is_original][\"entities\"])\n",
    "            thisround_context_qa_graph[\"relations\"].append(this_dialogue[\"round_original_question_subgraph\"][analysis_thisround_is_original][\"relations\"])\n",
    "            \n",
    "            # if previous round question is answerable, put all information in context, else just keep original question info, duplicated info will be filtered autmatically\n",
    "            if list_previous_round_answerabilty[context_round_i]:\n",
    "                thisround_context_qa_graph[\"entities\"].append(this_dialogue[\"round_subgraph\"][analysis_thisround_is_original][\"Question\"][\"entities\"])\n",
    "                thisround_context_qa_graph[\"relations\"].append(this_dialogue[\"round_subgraph\"][analysis_thisround_is_original][\"Question\"][\"relations\"])\n",
    "                thisround_context_qa_graph[\"entities\"].append(this_dialogue[\"round_subgraph\"][analysis_thisround_is_original][\"Answer\"][\"entities\"])\n",
    "                thisround_context_qa_graph[\"relations\"].append(this_dialogue[\"round_subgraph\"][analysis_thisround_is_original][\"Answer\"][\"relations\"])\n",
    "        ##### up\n",
    "        thisround_context_qa_graph[\"entities\"] = flatten(thisround_context_qa_graph[\"entities\"])\n",
    "        thisround_context_qa_graph[\"relations\"] = flatten(thisround_context_qa_graph[\"relations\"])\n",
    "\n",
    "        FLAG_self_resolvable, _ = self_resolvable(thisround_oriqa_q)   \n",
    "        FLAG_story_resolvable = story_resolvable(this_dialogue_story_content, thisround_oriqa_q)\n",
    "        FLAG_context_resolvable = context_resolvable(thisround_oriqa_q_graph, thisround_fullqa_q_graph, thisround_context_qa_graph)\n",
    "        ##### below\n",
    "        list_previous_round_answerabilty.append(FLAG_self_resolvable or FLAG_story_resolvable or FLAG_context_resolvable) and (\"unknown\" not in thisround_oriqa_a.lower())\n",
    "        ##### up\n",
    "        if FLAG_self_resolvable or FLAG_story_resolvable or FLAG_context_resolvable or (\"unknown\" in thisround_oriqa_a.lower()):\n",
    "            perturbed_dialogue[thisround_key][\"FLAG_answer_changed\"] = False\n",
    "            pass\n",
    "        else:\n",
    "            perturbed_dialogue[thisround_key][\"Answer_original\"] = thisround_oriqa_a\n",
    "            perturbed_dialogue[thisround_key][\"Answer\"] = \"unknown\"\n",
    "            perturbed_dialogue[thisround_key][\"FLAG_answer_changed\"] = True\n",
    "            update_answer_counter+=1\n",
    "\n",
    "        perturbed_dialogue[thisround_key][\"is_original_round\"] = thisround_is_original_round\n",
    "        \n",
    "        perturbed_dialogue[thisround_key][\"FLAG_self_resolvable\"] = FLAG_self_resolvable\n",
    "        perturbed_dialogue[thisround_key][\"FLAG_story_resolvable\"] = FLAG_story_resolvable\n",
    "        perturbed_dialogue[thisround_key][\"FLAG_context_resolvable\"] = FLAG_context_resolvable\n",
    "\n",
    "    dataset_new_dialogue[thisdialogue_key] = copy.deepcopy(perturbed_dialogue)\n",
    "        \n",
    "with open(\"data/P3_round_duplicate.json\", \"w\") as f:\n",
    "    json.dump(dataset_new_dialogue, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22d2dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P4: Dialogue round shuffle and reduce\n",
    "path_dataset = \"data/extracted_dev_all_final_update_3_strict.json\"\n",
    "dataset_dev_full= json.load(open(path_dataset))\n",
    "\n",
    "all_keys = list(dataset_dev_full.keys())[:]\n",
    "\n",
    "dataset_new_dialogue = {}\n",
    "\n",
    "update_answer_counter = 0\n",
    "\n",
    "for thisdialogue_key in tqdm.tqdm(all_keys):\n",
    "\n",
    "    this_dialogue = copy.deepcopy(dataset_dev_full[thisdialogue_key])\n",
    "    if this_dialogue[\"DATA_PROCESS_FLAG\"] >= 500: continue\n",
    "\n",
    "    original_qa = this_dialogue[\"original_qa\"]\n",
    "    this_dialogue_story_content = this_dialogue[\"story_material\"]\n",
    "\n",
    "    # make new dialogue\n",
    "    perturbed_dialogue, perturbed_dialogue_round_mapping, _ = round_reduce_shuffle(original_qa)\n",
    "    perturbed_dialogue_all_round_keys = list(perturbed_dialogue.keys())\n",
    "    ##### below\n",
    "    list_previous_round_answerabilty = [] \n",
    "    ##### up\n",
    "    for thisround_i, thisround_key in enumerate(perturbed_dialogue_all_round_keys):\n",
    "        thisround_is_original_round = perturbed_dialogue_round_mapping[thisround_key]\n",
    "\n",
    "        thisround_oriqa_q = perturbed_dialogue[thisround_key][\"Question\"]\n",
    "        thisround_oriqa_a = perturbed_dialogue[thisround_key][\"Answer\"]\n",
    "\n",
    "        thisround_oriqa_q_graph = this_dialogue[\"round_original_question_subgraph\"][thisround_is_original_round]\n",
    "        thisround_fullqa_q_graph = this_dialogue[\"round_subgraph\"][thisround_is_original_round][\"Question\"]\n",
    "\n",
    "        thisround_context_qa_graph = {\n",
    "            \"entities\":[],\n",
    "            \"relations\":[]\n",
    "        }\n",
    "        ##### below\n",
    "        for context_round_i in range(thisround_i): \n",
    "            analysis_thisround_is_original  = perturbed_dialogue_round_mapping[perturbed_dialogue_all_round_keys[context_round_i]]\n",
    "\n",
    "            thisround_context_qa_graph[\"entities\"].append(this_dialogue[\"round_original_question_subgraph\"][analysis_thisround_is_original][\"entities\"])\n",
    "            thisround_context_qa_graph[\"relations\"].append(this_dialogue[\"round_original_question_subgraph\"][analysis_thisround_is_original][\"relations\"])\n",
    "            \n",
    "            # if previous round question is answerable, put all information in context, else just keep original question info, duplicated info will be filtered autmatically\n",
    "            if list_previous_round_answerabilty[context_round_i]:\n",
    "                thisround_context_qa_graph[\"entities\"].append(this_dialogue[\"round_subgraph\"][analysis_thisround_is_original][\"Question\"][\"entities\"])\n",
    "                thisround_context_qa_graph[\"relations\"].append(this_dialogue[\"round_subgraph\"][analysis_thisround_is_original][\"Question\"][\"relations\"])\n",
    "                thisround_context_qa_graph[\"entities\"].append(this_dialogue[\"round_subgraph\"][analysis_thisround_is_original][\"Answer\"][\"entities\"])\n",
    "                thisround_context_qa_graph[\"relations\"].append(this_dialogue[\"round_subgraph\"][analysis_thisround_is_original][\"Answer\"][\"relations\"])\n",
    "        ##### up\n",
    "        thisround_context_qa_graph[\"entities\"] = flatten(thisround_context_qa_graph[\"entities\"])\n",
    "        thisround_context_qa_graph[\"relations\"] = flatten(thisround_context_qa_graph[\"relations\"])\n",
    "\n",
    "        FLAG_self_resolvable, _ = self_resolvable(thisround_oriqa_q)   \n",
    "        FLAG_story_resolvable = story_resolvable(this_dialogue_story_content, thisround_oriqa_q)\n",
    "        FLAG_context_resolvable = context_resolvable(thisround_oriqa_q_graph, thisround_fullqa_q_graph, thisround_context_qa_graph)\n",
    "        ##### below\n",
    "        list_previous_round_answerabilty.append(FLAG_self_resolvable or FLAG_story_resolvable or FLAG_context_resolvable) and (\"unknown\" not in thisround_oriqa_a.lower())\n",
    "        ##### up\n",
    "        if FLAG_self_resolvable or FLAG_story_resolvable or FLAG_context_resolvable or (\"unknown\" in thisround_oriqa_a.lower()):\n",
    "            perturbed_dialogue[thisround_key][\"FLAG_answer_changed\"] = False\n",
    "            pass\n",
    "        else:\n",
    "            perturbed_dialogue[thisround_key][\"Answer_original\"] = thisround_oriqa_a\n",
    "            perturbed_dialogue[thisround_key][\"Answer\"] = \"unknown\"\n",
    "            perturbed_dialogue[thisround_key][\"FLAG_answer_changed\"] = True\n",
    "            update_answer_counter+=1\n",
    "\n",
    "        perturbed_dialogue[thisround_key][\"is_original_round\"] = thisround_is_original_round\n",
    "        \n",
    "        perturbed_dialogue[thisround_key][\"FLAG_self_resolvable\"] = FLAG_self_resolvable\n",
    "        perturbed_dialogue[thisround_key][\"FLAG_story_resolvable\"] = FLAG_story_resolvable\n",
    "        perturbed_dialogue[thisround_key][\"FLAG_context_resolvable\"] = FLAG_context_resolvable\n",
    "\n",
    "    dataset_new_dialogue[thisdialogue_key] = copy.deepcopy(perturbed_dialogue)\n",
    "        \n",
    "with open(\"data/P4_round_reduce_shuffle.json\", \"w\") as f:\n",
    "    json.dump(dataset_new_dialogue, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5b7288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P5: Dialogue round shuffle and duplicate\n",
    "path_dataset = \"data/extracted_dev_all_final_update_3_strict.json\"\n",
    "dataset_dev_full= json.load(open(path_dataset))\n",
    "\n",
    "all_keys = list(dataset_dev_full.keys())[:]\n",
    "\n",
    "dataset_new_dialogue = {}\n",
    "\n",
    "update_answer_counter = 0\n",
    "\n",
    "for thisdialogue_key in tqdm.tqdm(all_keys):\n",
    "\n",
    "    this_dialogue = copy.deepcopy(dataset_dev_full[thisdialogue_key])\n",
    "    if this_dialogue[\"DATA_PROCESS_FLAG\"] >= 500: continue\n",
    "\n",
    "    original_qa = this_dialogue[\"original_qa\"]\n",
    "    this_dialogue_story_content = this_dialogue[\"story_material\"]\n",
    "\n",
    "    # make new dialogue\n",
    "    perturbed_dialogue, perturbed_dialogue_round_mapping, _ , _ = round_shuffle_duplicate(original_qa)\n",
    "    perturbed_dialogue_all_round_keys = list(perturbed_dialogue.keys())\n",
    "    ##### below\n",
    "    list_previous_round_answerabilty = [] \n",
    "    ##### up\n",
    "    for thisround_i, thisround_key in enumerate(perturbed_dialogue_all_round_keys):\n",
    "        thisround_is_original_round = perturbed_dialogue_round_mapping[thisround_key]\n",
    "\n",
    "        thisround_oriqa_q = perturbed_dialogue[thisround_key][\"Question\"]\n",
    "        thisround_oriqa_a = perturbed_dialogue[thisround_key][\"Answer\"]\n",
    "\n",
    "        thisround_oriqa_q_graph = this_dialogue[\"round_original_question_subgraph\"][thisround_is_original_round]\n",
    "        thisround_fullqa_q_graph = this_dialogue[\"round_subgraph\"][thisround_is_original_round][\"Question\"]\n",
    "\n",
    "        thisround_context_qa_graph = {\n",
    "            \"entities\":[],\n",
    "            \"relations\":[]\n",
    "        }\n",
    "        ##### below\n",
    "        for context_round_i in range(thisround_i): \n",
    "            analysis_thisround_is_original  = perturbed_dialogue_round_mapping[perturbed_dialogue_all_round_keys[context_round_i]]\n",
    "\n",
    "            thisround_context_qa_graph[\"entities\"].append(this_dialogue[\"round_original_question_subgraph\"][analysis_thisround_is_original][\"entities\"])\n",
    "            thisround_context_qa_graph[\"relations\"].append(this_dialogue[\"round_original_question_subgraph\"][analysis_thisround_is_original][\"relations\"])\n",
    "            \n",
    "            # if previous round question is answerable, put all information in context, else just keep original question info, duplicated info will be filtered autmatically\n",
    "            if list_previous_round_answerabilty[context_round_i]:\n",
    "                thisround_context_qa_graph[\"entities\"].append(this_dialogue[\"round_subgraph\"][analysis_thisround_is_original][\"Question\"][\"entities\"])\n",
    "                thisround_context_qa_graph[\"relations\"].append(this_dialogue[\"round_subgraph\"][analysis_thisround_is_original][\"Question\"][\"relations\"])\n",
    "                thisround_context_qa_graph[\"entities\"].append(this_dialogue[\"round_subgraph\"][analysis_thisround_is_original][\"Answer\"][\"entities\"])\n",
    "                thisround_context_qa_graph[\"relations\"].append(this_dialogue[\"round_subgraph\"][analysis_thisround_is_original][\"Answer\"][\"relations\"])\n",
    "        ##### up\n",
    "        thisround_context_qa_graph[\"entities\"] = flatten(thisround_context_qa_graph[\"entities\"])\n",
    "        thisround_context_qa_graph[\"relations\"] = flatten(thisround_context_qa_graph[\"relations\"])\n",
    "\n",
    "        FLAG_self_resolvable, _ = self_resolvable(thisround_oriqa_q)   \n",
    "        FLAG_story_resolvable = story_resolvable(this_dialogue_story_content, thisround_oriqa_q)\n",
    "        FLAG_context_resolvable = context_resolvable(thisround_oriqa_q_graph, thisround_fullqa_q_graph, thisround_context_qa_graph)\n",
    "        ##### below\n",
    "        list_previous_round_answerabilty.append(FLAG_self_resolvable or FLAG_story_resolvable or FLAG_context_resolvable) and (\"unknown\" not in thisround_oriqa_a.lower())\n",
    "        ##### up\n",
    "        if FLAG_self_resolvable or FLAG_story_resolvable or FLAG_context_resolvable or (\"unknown\" in thisround_oriqa_a.lower()):\n",
    "            perturbed_dialogue[thisround_key][\"FLAG_answer_changed\"] = False\n",
    "            pass\n",
    "        else:\n",
    "            perturbed_dialogue[thisround_key][\"Answer_original\"] = thisround_oriqa_a\n",
    "            perturbed_dialogue[thisround_key][\"Answer\"] = \"unknown\"\n",
    "            perturbed_dialogue[thisround_key][\"FLAG_answer_changed\"] = True\n",
    "            update_answer_counter+=1\n",
    "\n",
    "        perturbed_dialogue[thisround_key][\"is_original_round\"] = thisround_is_original_round\n",
    "        \n",
    "        perturbed_dialogue[thisround_key][\"FLAG_self_resolvable\"] = FLAG_self_resolvable\n",
    "        perturbed_dialogue[thisround_key][\"FLAG_story_resolvable\"] = FLAG_story_resolvable\n",
    "        perturbed_dialogue[thisround_key][\"FLAG_context_resolvable\"] = FLAG_context_resolvable\n",
    "\n",
    "    dataset_new_dialogue[thisdialogue_key] = copy.deepcopy(perturbed_dialogue)\n",
    "        \n",
    "with open(\"data/P5_round_shuffle_duplicate.json\", \"w\") as f:\n",
    "    json.dump(dataset_new_dialogue, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a118ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline: METAL\n",
    "\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "def synonym_replacement(input_text): #word-level\n",
    "    words = input_text.split()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        synonyms = []\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for lemma in syn.lemmas():\n",
    "                synonyms.append(lemma.name())\n",
    "        if synonyms:\n",
    "            new_words.append(random.choice(synonyms))\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return ' '.join(new_words)\n",
    "\n",
    "def introduce_typos(input_string): #character-level\n",
    "    typo_probability = 0.1\n",
    "    typoed_string = \"\"\n",
    "    for char in input_string:\n",
    "        if random.uniform(0, 1) < typo_probability:\n",
    "            typoed_string += chr(random.randint(97, 122))#random lowercase character\n",
    "        else:\n",
    "            typoed_string += char\n",
    "    return typoed_string\n",
    "\n",
    "def add_words(input_string):\n",
    "    input_split = input_string.split()\n",
    "    random_word = random.choice([\"Apple\", \"Pear\", \"Banana\", \"Grape\"])\n",
    "    input_split.insert(random.randint(0, len(input_split)), random_word)\n",
    "    output_text = \" \".join(input_split)\n",
    "    return output_text\n",
    "\n",
    "def to_leet(input_string): #character-level\n",
    "    leet_mapping = {\n",
    "        'a': '4',\n",
    "        'e': '3',\n",
    "        'i': '1',\n",
    "        'o': '0'\n",
    "    }\n",
    "    leet_words = []\n",
    "    leet_probability = 0.2\n",
    "    words = input_string.split()\n",
    "    for word in words:\n",
    "        if random.uniform(0, 1) < leet_probability:\n",
    "            leet_text = ''\n",
    "            for char in word:\n",
    "                lowercase_char = char.lower()\n",
    "                if lowercase_char in leet_mapping:\n",
    "                    leet_text += leet_mapping[lowercase_char]\n",
    "                else:\n",
    "                    leet_text += char\n",
    "            leet_words.append(leet_text)\n",
    "        else:\n",
    "            leet_words.append(word)    \n",
    "    return ' '.join(leet_words)\n",
    "\n",
    "#######################\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "import copy\n",
    "\n",
    "################## generation below ##################\n",
    "import json\n",
    "import tqdm\n",
    "import copy\n",
    "\n",
    "from multi_turn_test.MultiTurnConversation import score_utils\n",
    "\n",
    "score_tool = score_utils()\n",
    "\n",
    "path_dataset = \"data/extracted_dev_all_final_update_3.json\"\n",
    "dataset_dev_full= json.load(open(path_dataset))\n",
    "\n",
    "dataset_dev_full_original = json.load(open(\"data/MR0_round_original.json\"))\n",
    "\n",
    "all_keys = list(dataset_dev_full.keys())[:]\n",
    "\n",
    "dataset_new_dialogue_synonym = {}\n",
    "dataset_new_dialogue_typo = {}\n",
    "dataset_new_dialogue_leet = {}\n",
    "dataset_new_dialogue_add_words = {}\n",
    "\n",
    "change_synonym = 0\n",
    "change_typo = 0\n",
    "change_leet = 0\n",
    "change_add_words = 0\n",
    "\n",
    "short_question_counter = 0\n",
    "long_question_counter = 0\n",
    "\n",
    "SYNONYM = True\n",
    "TYPO = True\n",
    "LEET = True\n",
    "ADD_WORDS = True\n",
    "\n",
    "SS_THRESHOLD = 0.6\n",
    "ShortPert = False\n",
    "\n",
    "print(\"SS_THRESHOLD:\", SS_THRESHOLD, \" ShortPert:\", ShortPert)\n",
    "\n",
    "for thisdialogue_key in tqdm.tqdm(all_keys):\n",
    "    # if update_answer_counter/10 == 0: print(\"update_answer_counter:\",update_answer_counter)\n",
    "\n",
    "    this_dialogue = copy.deepcopy(dataset_dev_full[thisdialogue_key])\n",
    "    if this_dialogue[\"DATA_PROCESS_FLAG\"] >= 500: continue\n",
    "\n",
    "    original_qa = this_dialogue[\"original_qa\"]\n",
    "    this_dialogue_story_content = this_dialogue[\"story_material\"]\n",
    "\n",
    "    # make new dialogue\n",
    "    perturbed_dialogue = original_qa\n",
    "\n",
    "    perturbed_dialogue_synonym = copy.deepcopy(original_qa)\n",
    "    perturbed_dialogue_typo= copy.deepcopy(original_qa)\n",
    "    perturbed_dialogue_leet = copy.deepcopy(original_qa)\n",
    "    perturbed_dialogue_add_words = copy.deepcopy(original_qa)\n",
    "\n",
    "    perturbed_dialogue_round_mapping = {}\n",
    "    perturbed_dialogue_all_round_keys = list(perturbed_dialogue.keys())\n",
    "    for key in perturbed_dialogue_all_round_keys:\n",
    "        perturbed_dialogue_round_mapping[key] = key\n",
    "\n",
    "    for thisround_i, thisround_key in enumerate(perturbed_dialogue_all_round_keys):\n",
    "        # make new rounds\n",
    "        thisround_is_original_round = perturbed_dialogue_round_mapping[thisround_key]\n",
    "\n",
    "        thisround_oriqa_q = perturbed_dialogue[thisround_key][\"Question\"]\n",
    "\n",
    "        doc = nlp(thisround_oriqa_q)\n",
    "\n",
    "        long_question = True\n",
    "        word_count = len([token for token in doc if not token.is_punct])\n",
    "        if word_count <= 3: \n",
    "            long_question = False\n",
    "            short_question_counter+=1\n",
    "        else:\n",
    "            long_question_counter+=1\n",
    "\n",
    "        if SYNONYM:\n",
    "            if ShortPert or long_question:\n",
    "                perturbed_synonym_q = synonym_replacement(thisround_oriqa_q)\n",
    "                if score_tool.semantic_similarity(perturbed_synonym_q, thisround_oriqa_q) > SS_THRESHOLD: # ensure readability\n",
    "                    thisround_synonym_q = perturbed_synonym_q\n",
    "                    change_synonym+=1\n",
    "                else:\n",
    "                    thisround_synonym_q = thisround_oriqa_q\n",
    "            else:\n",
    "                thisround_synonym_q = thisround_oriqa_q\n",
    "        else:\n",
    "            thisround_synonym_q = thisround_oriqa_q\n",
    "\n",
    "        if TYPO:\n",
    "            if ShortPert or long_question:\n",
    "                perturbed_typo_q = introduce_typos(thisround_oriqa_q)\n",
    "                if score_tool.semantic_similarity(perturbed_typo_q, thisround_oriqa_q) > SS_THRESHOLD: # ensure readability\n",
    "                    thisround_typo_q = perturbed_typo_q\n",
    "                    change_typo+=1\n",
    "                else:\n",
    "                    thisround_typo_q = thisround_oriqa_q\n",
    "            else:\n",
    "                thisround_typo_q = thisround_oriqa_q\n",
    "        else:\n",
    "            thisround_typo_q = thisround_oriqa_q\n",
    "\n",
    "        \n",
    "        if LEET:\n",
    "            if ShortPert or long_question:\n",
    "                perturbed_leet_q = to_leet(thisround_oriqa_q)\n",
    "                if score_tool.semantic_similarity(perturbed_leet_q, thisround_oriqa_q) > SS_THRESHOLD: # ensure readability\n",
    "                    thisround_leet_q = perturbed_leet_q\n",
    "                    change_leet+=1\n",
    "                else:\n",
    "                    thisround_leet_q = thisround_oriqa_q\n",
    "            else:\n",
    "                thisround_leet_q = thisround_oriqa_q\n",
    "        else:\n",
    "            thisround_leet_q = thisround_oriqa_q\n",
    "\n",
    "        # if ADD_WORDS and long_question:\n",
    "        if ADD_WORDS:\n",
    "            if ShortPert or long_question:\n",
    "                perturbed_add_words_q = add_words(thisround_oriqa_q)\n",
    "                if score_tool.semantic_similarity(perturbed_add_words_q, thisround_oriqa_q) > SS_THRESHOLD: # ensure readability\n",
    "                    thisround_add_words_q = perturbed_add_words_q\n",
    "                    change_add_words+=1\n",
    "                else:\n",
    "                    thisround_add_words_q = thisround_oriqa_q\n",
    "            else:\n",
    "                thisround_add_words_q = thisround_oriqa_q\n",
    "        else:\n",
    "            thisround_add_words_q = thisround_oriqa_q\n",
    "\n",
    "        perturbed_dialogue_synonym[thisround_key][\"Question\"] = thisround_synonym_q\n",
    "        perturbed_dialogue_synonym[thisround_key][\"Original_question\"] = thisround_oriqa_q\n",
    "        perturbed_dialogue_synonym[thisround_key][\"FLAG_question_changed\"] = True if thisround_synonym_q != thisround_oriqa_q else False\n",
    "        perturbed_dialogue_synonym[thisround_key][\"FLAG_answer_changed\"] = False\n",
    "        perturbed_dialogue_synonym[thisround_key][\"is_original_round\"] = thisround_is_original_round\n",
    "        perturbed_dialogue_synonym[thisround_key][\"FLAG_self_resolvable\"] = dataset_dev_full_original[thisdialogue_key][thisround_key][\"FLAG_self_resolvable\"]\n",
    "        perturbed_dialogue_synonym[thisround_key][\"FLAG_story_resolvable\"] = dataset_dev_full_original[thisdialogue_key][thisround_key][\"FLAG_story_resolvable\"]\n",
    "        perturbed_dialogue_synonym[thisround_key][\"FLAG_context_resolvable\"] = dataset_dev_full_original[thisdialogue_key][thisround_key][\"FLAG_context_resolvable\"]\n",
    "\n",
    "        perturbed_dialogue_typo[thisround_key][\"Question\"] = thisround_typo_q\n",
    "        perturbed_dialogue_typo[thisround_key][\"Original_question\"] = thisround_oriqa_q\n",
    "        perturbed_dialogue_typo[thisround_key][\"FLAG_question_changed\"] = True if thisround_typo_q != thisround_oriqa_q else False\n",
    "        perturbed_dialogue_typo[thisround_key][\"FLAG_answer_changed\"] = False\n",
    "        perturbed_dialogue_typo[thisround_key][\"is_original_round\"] = thisround_is_original_round\n",
    "        perturbed_dialogue_typo[thisround_key][\"FLAG_self_resolvable\"] = dataset_dev_full_original[thisdialogue_key][thisround_key][\"FLAG_self_resolvable\"]\n",
    "        perturbed_dialogue_typo[thisround_key][\"FLAG_story_resolvable\"] = dataset_dev_full_original[thisdialogue_key][thisround_key][\"FLAG_story_resolvable\"]\n",
    "        perturbed_dialogue_typo[thisround_key][\"FLAG_context_resolvable\"] = dataset_dev_full_original[thisdialogue_key][thisround_key][\"FLAG_context_resolvable\"]\n",
    "\n",
    "        perturbed_dialogue_leet[thisround_key][\"Question\"] = thisround_leet_q\n",
    "        perturbed_dialogue_leet[thisround_key][\"Original_question\"] = thisround_oriqa_q\n",
    "        perturbed_dialogue_leet[thisround_key][\"FLAG_question_changed\"] = True if thisround_leet_q != thisround_oriqa_q else False\n",
    "        perturbed_dialogue_leet[thisround_key][\"FLAG_answer_changed\"] = False\n",
    "        perturbed_dialogue_leet[thisround_key][\"is_original_round\"] = thisround_is_original_round\n",
    "        perturbed_dialogue_leet[thisround_key][\"FLAG_self_resolvable\"] = dataset_dev_full_original[thisdialogue_key][thisround_key][\"FLAG_self_resolvable\"]\n",
    "        perturbed_dialogue_leet[thisround_key][\"FLAG_story_resolvable\"] = dataset_dev_full_original[thisdialogue_key][thisround_key][\"FLAG_story_resolvable\"]\n",
    "        perturbed_dialogue_leet[thisround_key][\"FLAG_context_resolvable\"] = dataset_dev_full_original[thisdialogue_key][thisround_key][\"FLAG_context_resolvable\"]\n",
    "\n",
    "        perturbed_dialogue_add_words[thisround_key][\"Question\"] = thisround_add_words_q\n",
    "        perturbed_dialogue_add_words[thisround_key][\"Original_question\"] = thisround_oriqa_q\n",
    "        perturbed_dialogue_add_words[thisround_key][\"FLAG_question_changed\"] = True if thisround_add_words_q != thisround_oriqa_q else False\n",
    "        perturbed_dialogue_add_words[thisround_key][\"FLAG_answer_changed\"] = False\n",
    "        perturbed_dialogue_add_words[thisround_key][\"is_original_round\"] = thisround_is_original_round\n",
    "        perturbed_dialogue_add_words[thisround_key][\"FLAG_self_resolvable\"] = dataset_dev_full_original[thisdialogue_key][thisround_key][\"FLAG_self_resolvable\"]\n",
    "        perturbed_dialogue_add_words[thisround_key][\"FLAG_story_resolvable\"] = dataset_dev_full_original[thisdialogue_key][thisround_key][\"FLAG_story_resolvable\"]\n",
    "        perturbed_dialogue_add_words[thisround_key][\"FLAG_context_resolvable\"] = dataset_dev_full_original[thisdialogue_key][thisround_key][\"FLAG_context_resolvable\"]\n",
    "\n",
    "    dataset_new_dialogue_synonym[thisdialogue_key] = copy.deepcopy(perturbed_dialogue_synonym)\n",
    "    dataset_new_dialogue_typo[thisdialogue_key] = copy.deepcopy(perturbed_dialogue_typo)\n",
    "    dataset_new_dialogue_leet[thisdialogue_key] = copy.deepcopy(perturbed_dialogue_leet)\n",
    "    dataset_new_dialogue_add_words[thisdialogue_key] = copy.deepcopy(perturbed_dialogue_add_words)\n",
    "\n",
    "\n",
    "print(\"change_synonym:{}, change_typo:{}, change_leet: {}, add words: {}, short questions: {}, long questions:{}\".format(change_synonym, change_typo, change_leet, change_add_words, short_question_counter, long_question_counter))\n",
    "\n",
    "\n",
    "if ShortPert:\n",
    "    middle_name = \"SP_s0\"+str(int(SS_THRESHOLD*10))\n",
    "else:\n",
    "    middle_name = \"SNP_s0\"+str(int(SS_THRESHOLD*10))\n",
    "\n",
    "with open(f\"data/MR10_{middle_name}_synonym_replacement.json\", \"w\") as f:\n",
    "    json.dump(dataset_new_dialogue_synonym, f, indent=4)\n",
    "with open(f\"data/MR11_{middle_name}_introduce_typos.json\", \"w\") as f:\n",
    "    json.dump(dataset_new_dialogue_typo, f, indent=4)\n",
    "with open(f\"data/MR12_{middle_name}_to_leet.json\", \"w\") as f:\n",
    "    json.dump(dataset_new_dialogue_leet, f, indent=4)\n",
    "with open(f\"data/MR13_{middle_name}_add_words.json\", \"w\") as f:\n",
    "    json.dump(dataset_new_dialogue_add_words, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
